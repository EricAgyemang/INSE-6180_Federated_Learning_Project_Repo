{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d989b3-3cae-4e5a-9aaf-8e9cebc606a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Convolution Neural Netwook (CNN) with the Federated Averaging Optimization Algorithm with\n",
    "# 10 Virtual clients have been selected to train the models at each round with a limited client drop-rate\n",
    "# hence we should expect possibly less than 10 clients chosen at random at any given round to train.\n",
    "# These are under the communication of an virtually simulated orchastrated server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b623799b-3151-4c0a-ab88-b23abcd3eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import syft as sy\n",
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from FLDataset.FLDataset import load_dataset\n",
    "from FLDataset.FLDataset import getActualImgs\n",
    "from FLDataset.utils import averageModels, averageGradients\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9613e97-3a23-47a5-b932-739743311177",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.images = 60000\n",
    "        self.clients = 10\n",
    "        self.epochs = 6\n",
    "        self.local_batches = 64\n",
    "        self.lr = 0.01\n",
    "        self.C = 0.8\n",
    "        self.drop_rate = 0.2\n",
    "        self.torch_seed = 0\n",
    "        self.log_interval = 10\n",
    "        self.iid = 'iid'\n",
    "        self.split_size = int(self.images / self.clients)\n",
    "        self.samples = self.split_size / self.images \n",
    "        self.use_cuda = False\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad21a224-9f35-4a58-82e4-48e816ddddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a virtual Server called hook\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "# Create virtual workers for clients\n",
    "clients = []\n",
    "\n",
    "for i in range(args.clients):\n",
    "    clients.append({'hook': sy.VirtualWorker(hook, id=\"client{}\".format(i+1))})\n",
    "\n",
    "# Load dataset and split between clients\n",
    "global_train, global_test, train_group, test_group = load_dataset(args.clients, args.iid)\n",
    "\n",
    "for inx, client in enumerate(clients):\n",
    "# Use get() to safely access the 'trainset' and 'testset' keys, setting them to None if they don't exist\n",
    "    client['trainset'] = getActualImgs(global_train, list(train_group[inx])[:200], args.local_batches)\n",
    "    client['testset'] = getActualImgs(global_test, list(test_group[inx]), args.local_batches)\n",
    "\n",
    "    # Ensure that 'trainset' and 'testset' keys are not None and have valid data\n",
    "    if client['trainset'] is None or client['testset'] is None:\n",
    "        raise ValueError(f\"Client {client['hook'].id} does not have valid train or test data.\")\n",
    "\n",
    "    # Calculate the total samples across all clients with valid 'trainset' data\n",
    "    total_trainset_samples = sum(len(c['trainset']) for c in clients if 'trainset' in c and c['trainset'] is not None)\n",
    "\n",
    "    # Calculate the proportion of samples for the client based on their trainset length\n",
    "    client['samples'] = len(client['trainset']) / total_trainset_samples\n",
    "    \n",
    "# Define the global test data loader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "global_test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "global_test_loader = DataLoader(global_test_dataset, batch_size=args.local_batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67fc88d6-63fa-4c05-b242-68e421c98da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First convolutional layer\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "        # First fully connected layer\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db0502ea-3230-4abd-9dd6-528c85411060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, clients, device, epoch):\n",
    "    client['model'].train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(client['trainset']):\n",
    "\n",
    "        data = data.send(client['hook'])\n",
    "        target = target.send(client['hook'])\n",
    "        client['model'].send(data.location)\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        client['optim'].zero_grad()\n",
    "        output = client['model'](data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        client['model'].get() \n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get() \n",
    "            progress = (batch_idx+1) * args.local_batches\n",
    "            print('Model {} Train Epoch: {} \\tLoss: {:.6f}'.format(\n",
    "                client['hook'].id, epoch, loss))   \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a6fe230-882f-4ffc-ab7c-ec2ab383033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the test function that will be implemented\n",
    "def test(args, model, device, test_loader, name):\n",
    "    model.eval()   \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    print(f\"\\nTesting {name} model with {len(test_loader.dataset)} samples\")\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100 * (1 - (correct / len(test_loader.dataset)))\n",
    "    print('\\nTest set: Average loss for {} model: {:.2f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        name, test_loss, correct, len(test_loader.dataset), accuracy))\n",
    "\n",
    "    print(f\"\\n{name} Model Prediction Error: {(100-accuracy):.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d8e1c10-a026-45c7-aa60-9a977cc5e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedSGDOptim(optim.Optimizer):\n",
    "    def __init__(self, params, lr=args.lr):\n",
    "        defaults = dict(lr=lr)\n",
    "        super(FedSGDOptim, self).__init__(params, defaults)\n",
    "        \n",
    "    def step(self, grad_model=None, closure = None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            lr = group['lr']\n",
    "            for p in zip(group['params'], list(grad_model.parameters())):\n",
    "                if p[0].grad is None:\n",
    "                    continue\n",
    "                p[0].data.add_(-group['lr'], p[1].grad.data.clone())\n",
    "                \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cda0cecb-1f00-4519-83fa-7391a7b12cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEDERATED LEARNING MODEL ROUND: 1\n",
      "Model client1 Train Epoch: 1 \tLoss: 2.331440\n",
      "Model client2 Train Epoch: 1 \tLoss: 2.344059\n",
      "Model client3 Train Epoch: 1 \tLoss: 2.340851\n",
      "Model client4 Train Epoch: 1 \tLoss: 2.307723\n",
      "Model client5 Train Epoch: 1 \tLoss: 2.301387\n",
      "Model client6 Train Epoch: 1 \tLoss: 2.282655\n",
      "Model client7 Train Epoch: 1 \tLoss: 2.302820\n",
      "Model client8 Train Epoch: 1 \tLoss: 2.283996\n",
      "Model client9 Train Epoch: 1 \tLoss: 2.314949\n",
      "Model client10 Train Epoch: 1 \tLoss: 2.305409\n",
      "\n",
      "Testing Global model with 10000 samples\n",
      "\n",
      "Test set: Average loss for Global model: 2.31, Accuracy: 1004/10000 (89.96%)\n",
      "\n",
      "\n",
      "Global Model Prediction Error: 10.04%\n",
      "\n",
      "\n",
      "Testing Global model with 10000 samples\n",
      "\n",
      "Test set: Average loss for Global model: 2.30, Accuracy: 1095/10000 (89.05%)\n",
      "\n",
      "\n",
      "Global Model Prediction Error: 10.95%\n",
      "\n",
      "FEDERATED LEARNING MODEL ROUND: 2\n",
      "Model client1 Train Epoch: 2 \tLoss: 2.307828\n",
      "Model client2 Train Epoch: 2 \tLoss: 2.320753\n",
      "Model client3 Train Epoch: 2 \tLoss: 2.319476\n",
      "Model client4 Train Epoch: 2 \tLoss: 2.303223\n",
      "Model client5 Train Epoch: 2 \tLoss: 2.313305\n",
      "Model client6 Train Epoch: 2 \tLoss: 2.293047\n",
      "Model client7 Train Epoch: 2 \tLoss: 2.303722\n",
      "Model client8 Train Epoch: 2 \tLoss: 2.287117\n",
      "Model client9 Train Epoch: 2 \tLoss: 2.284730\n",
      "Model client10 Train Epoch: 2 \tLoss: 2.306644\n",
      "\n",
      "Testing Global model with 10000 samples\n",
      "\n",
      "Test set: Average loss for Global model: 2.30, Accuracy: 1095/10000 (89.05%)\n",
      "\n",
      "\n",
      "Global Model Prediction Error: 10.95%\n",
      "\n",
      "\n",
      "Testing Global model with 10000 samples\n",
      "\n",
      "Test set: Average loss for Global model: 2.29, Accuracy: 1623/10000 (83.77%)\n",
      "\n",
      "\n",
      "Global Model Prediction Error: 16.23%\n",
      "\n",
      "FEDERATED LEARNING MODEL ROUND: 3\n",
      "Model client1 Train Epoch: 3 \tLoss: 2.285104\n",
      "Model client2 Train Epoch: 3 \tLoss: 2.279017\n",
      "Model client3 Train Epoch: 3 \tLoss: 2.287313\n",
      "Model client4 Train Epoch: 3 \tLoss: 2.269849\n",
      "Model client5 Train Epoch: 3 \tLoss: 2.282820\n",
      "Model client6 Train Epoch: 3 \tLoss: 2.299764\n",
      "Model client7 Train Epoch: 3 \tLoss: 2.288023\n",
      "Model client8 Train Epoch: 3 \tLoss: 2.282416\n",
      "Model client9 Train Epoch: 3 \tLoss: 2.309655\n",
      "Model client10 Train Epoch: 3 \tLoss: 2.293811\n",
      "\n",
      "Testing Global model with 10000 samples\n",
      "\n",
      "Test set: Average loss for Global model: 2.29, Accuracy: 1623/10000 (83.77%)\n",
      "\n",
      "\n",
      "Global Model Prediction Error: 16.23%\n",
      "\n",
      "\n",
      "Testing Global model with 10000 samples\n",
      "\n",
      "Test set: Average loss for Global model: 2.28, Accuracy: 1931/10000 (80.69%)\n",
      "\n",
      "\n",
      "Global Model Prediction Error: 19.31%\n",
      "\n",
      "FEDERATED LEARNING MODEL ROUND: 4\n",
      "Model client1 Train Epoch: 4 \tLoss: 2.272238\n",
      "Model client2 Train Epoch: 4 \tLoss: 2.280136\n",
      "Model client3 Train Epoch: 4 \tLoss: 2.277983\n",
      "Model client4 Train Epoch: 4 \tLoss: 2.264696\n",
      "Model client5 Train Epoch: 4 \tLoss: 2.280919\n",
      "Model client6 Train Epoch: 4 \tLoss: 2.291258\n",
      "Model client7 Train Epoch: 4 \tLoss: 2.275669\n",
      "Model client8 Train Epoch: 4 \tLoss: 2.276581\n",
      "Model client9 Train Epoch: 4 \tLoss: 2.275028\n",
      "Model client10 Train Epoch: 4 \tLoss: 2.278976\n",
      "\n",
      "Testing Global model with 10000 samples\n",
      "\n",
      "Test set: Average loss for Global model: 2.28, Accuracy: 1931/10000 (80.69%)\n",
      "\n",
      "\n",
      "Global Model Prediction Error: 19.31%\n",
      "\n",
      "\n",
      "Testing Global model with 10000 samples\n",
      "\n",
      "Test set: Average loss for Global model: 2.26, Accuracy: 1765/10000 (82.35%)\n",
      "\n",
      "\n",
      "Global Model Prediction Error: 17.65%\n",
      "\n",
      "FEDERATED LEARNING MODEL ROUND: 5\n",
      "Model client1 Train Epoch: 5 \tLoss: 2.261732\n",
      "Model client2 Train Epoch: 5 \tLoss: 2.237570\n",
      "Model client3 Train Epoch: 5 \tLoss: 2.267959\n",
      "Model client4 Train Epoch: 5 \tLoss: 2.250082\n",
      "Model client5 Train Epoch: 5 \tLoss: 2.263333\n",
      "Model client6 Train Epoch: 5 \tLoss: 2.271745\n",
      "Model client7 Train Epoch: 5 \tLoss: 2.250592\n",
      "Model client8 Train Epoch: 5 \tLoss: 2.272189\n",
      "Model client9 Train Epoch: 5 \tLoss: 2.249589\n",
      "Model client10 Train Epoch: 5 \tLoss: 2.257617\n",
      "\n",
      "Testing Global model with 10000 samples\n",
      "\n",
      "Test set: Average loss for Global model: 2.26, Accuracy: 1765/10000 (82.35%)\n",
      "\n",
      "\n",
      "Global Model Prediction Error: 17.65%\n",
      "\n",
      "\n",
      "Testing Global model with 10000 samples\n",
      "\n",
      "Test set: Average loss for Global model: 2.25, Accuracy: 1166/10000 (88.34%)\n",
      "\n",
      "\n",
      "Global Model Prediction Error: 11.66%\n",
      "\n",
      "FEDERATED LEARNING MODEL ROUND: 6\n",
      "Model client1 Train Epoch: 6 \tLoss: 2.223793\n",
      "Model client2 Train Epoch: 6 \tLoss: 2.236387\n",
      "Model client3 Train Epoch: 6 \tLoss: 2.242355\n",
      "Model client4 Train Epoch: 6 \tLoss: 2.269354\n",
      "Model client5 Train Epoch: 6 \tLoss: 2.252005\n",
      "Model client6 Train Epoch: 6 \tLoss: 2.267265\n",
      "Model client7 Train Epoch: 6 \tLoss: 2.252071\n",
      "Model client8 Train Epoch: 6 \tLoss: 2.247808\n",
      "Model client9 Train Epoch: 6 \tLoss: 2.247916\n",
      "Model client10 Train Epoch: 6 \tLoss: 2.278953\n",
      "\n",
      "Testing Global model with 10000 samples\n",
      "\n",
      "Test set: Average loss for Global model: 2.25, Accuracy: 1166/10000 (88.34%)\n",
      "\n",
      "\n",
      "Global Model Prediction Error: 11.66%\n",
      "\n",
      "\n",
      "Testing Global model with 10000 samples\n",
      "\n",
      "Test set: Average loss for Global model: 2.24, Accuracy: 1094/10000 (89.06%)\n",
      "\n",
      "\n",
      "Global Model Prediction Error: 10.94%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.torch_seed)\n",
    "global_model = Net().to(device)\n",
    "optimizer = FedSGDOptim(global_model.parameters(), lr=args.lr)\n",
    "grad_model = Net().to(device)\n",
    "\n",
    "\n",
    "for client in clients:\n",
    "    torch.manual_seed(args.torch_seed)\n",
    "    client['model'] = Net().to(device)\n",
    "    client['optim'] = optim.SGD(client['model'].parameters(), lr=args.lr)\n",
    "\n",
    "    \n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(f\"FEDERATED LEARNING MODEL ROUND: {epoch}\")\n",
    "    \n",
    "    for client in clients:\n",
    "        train(args, client, device, epoch)\n",
    "        \n",
    "    grad_model = averageGradients(global_model, clients)\n",
    "    \n",
    "    # Testing the average model\n",
    "    test(args, global_model, device, global_test_loader, 'Global')\n",
    "    optimizer.step(grad_model) # Call the optimizer \n",
    "    test(args, global_model, device, global_test_loader, 'Global') # Check output after the optimizer call\n",
    "    \n",
    "    for client in clients:\n",
    "        client['model'].load_state_dict(global_model.state_dict())\n",
    "    \n",
    "if (args.save_model):\n",
    "    torch.save(global_model.state_dict(), \"FedSGD.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb88f5e-37d4-41c9-bdaf-7ca1307c6f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
