{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff254045-812f-4264-bd73-8fa866b2db83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "client_update() missing 2 required positional arguments: 'device' and 'client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14971/3506416900.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mselected_clients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_selected_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_clients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mclient_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0;31m# Aggregate client models and update the global model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mglobal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: client_update() missing 2 required positional arguments: 'device' and 'client'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import syft as sy\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from FLDataset.FLDataset import load_dataset\n",
    "from FLDataset.FLDataset import getActualImgs\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Define Arguments class\n",
    "class Arguments:\n",
    "    def __init__(self):\n",
    "        self.images = 60000\n",
    "        self.clients = 10\n",
    "        self.rounds = 10\n",
    "        self.local_batches = 64\n",
    "        self.k_neighbors = 5\n",
    "        self.C = 0.8\n",
    "        self.drop_rate = 0.2\n",
    "        self.torch_seed = 0\n",
    "        self.log_interval = 10\n",
    "        self.iid = 'iid'\n",
    "        self.split_size = int(self.images / self.clients)\n",
    "        self.samples = self.split_size / self.images\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "device = torch.device(\"cuda\" if args.use_cuda else \"cpu\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(args.torch_seed)\n",
    "np.random.seed(args.torch_seed)\n",
    "random.seed(args.torch_seed)\n",
    "\n",
    "# Initialize hook and clients\n",
    "hook = sy.TorchHook(torch)\n",
    "clients = [sy.VirtualWorker(hook, id=f\"client{i + 1}\") for i in range(args.clients)]\n",
    "\n",
    "# Load dataset and split into clients\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "global_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "global_test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Split global dataset into client datasets\n",
    "client_datasets = random_split(global_dataset, [args.split_size] * args.clients)\n",
    "\n",
    "# Define the KNN class\n",
    "class KNN:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.nn_model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # Convert data to numpy arrays\n",
    "        self.X_train = np.array(X_train)\n",
    "        self.y_train = np.array(y_train)\n",
    "        # Fit nearest neighbors model\n",
    "        self.nn_model = NearestNeighbors(n_neighbors=self.k, metric='euclidean')\n",
    "        self.nn_model.fit(self.X_train)\n",
    "\n",
    "    def predict(self, X_test, batch_size=100):\n",
    "        # Convert data to numpy arrays\n",
    "        if isinstance(X_test, list):\n",
    "            X_test = np.array(X_test)\n",
    "        else:\n",
    "            X_test = np.array(X_test)\n",
    "\n",
    "        num_samples = X_test.shape[0]\n",
    "        predictions = []\n",
    "\n",
    "        # Process predictions in smaller batches\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_end = min(i + batch_size, num_samples)\n",
    "            X_test_batch = X_test[i:batch_end]\n",
    "\n",
    "            # Find k-nearest neighbors for the batch\n",
    "            distances, indices = self.nn_model.kneighbors(X_test_batch)\n",
    "            \n",
    "            # Predict the mode (most common label) among the k-nearest neighbors\n",
    "            for index_list in indices:\n",
    "                k_labels = self.y_train[index_list]\n",
    "                counter = Counter(k_labels)\n",
    "                most_common_label = counter.most_common(1)[0][0]\n",
    "                predictions.append(most_common_label)\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "# Initialize clients with datasets and models\n",
    "for i, client in enumerate(clients):\n",
    "    client.trainset = DataLoader(client_datasets[i], batch_size=args.local_batches, shuffle=True)\n",
    "    client.model = KNN(k=args.k_neighbors)\n",
    "\n",
    "# Create global test loader\n",
    "global_test_loader = DataLoader(global_test_dataset, batch_size=args.local_batches, shuffle=False)\n",
    "\n",
    "# Client update function\n",
    "# def client_update(client):\n",
    "#     train_loader = client.trainset\n",
    "#     model = client.model\n",
    "#     X_train, y_train = [], []\n",
    "#     for data, target in train_loader:\n",
    "#         data = data.view(data.shape[0], -1).numpy()\n",
    "#         X_train.extend(data)\n",
    "#         y_train.extend(target.numpy())\n",
    "#     model.fit(X_train, y_train)\n",
    "#     print(f\"Client {client.id} trained local KNN model\")\n",
    "\n",
    "def client_update(args, device, client):\n",
    "    train_loader = client.trainset\n",
    "    model = client.model\n",
    "    X_train, y_train = [], []\n",
    "    \n",
    "    # Collect training data and labels from the DataLoader\n",
    "    for data, target in train_loader:\n",
    "        # Convert data to a flat array format and append it to X_train\n",
    "        data = data.view(data.shape[0], -1).numpy()\n",
    "        X_train.extend(data)\n",
    "        # Append labels to y_train\n",
    "        y_train.extend(target.numpy())\n",
    "    \n",
    "    # Fit the local KNN model with the collected training data and labels\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"Client {client.id} trained local KNN model\")\n",
    "    \n",
    "    # Iterate over rounds (epochs) and batches for logging purposes\n",
    "    for epoch in range(1, args.rounds + 1):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Move data and target to the appropriate device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Convert data to a flat array format suitable for model predictions\n",
    "            X_test = data.view(data.shape[0], -1).cpu().numpy()\n",
    "            y_test = target.cpu().numpy()\n",
    "            \n",
    "            # Predict using the client's KNN model\n",
    "            pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate accuracy by comparing predicted labels with the actual labels\n",
    "            accuracy = np.mean(pred == y_test) * 100\n",
    "            \n",
    "            # Log training progress at the specified interval\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Client {} Train round: {} [{}/{} ({:.0f}%)] - Accuracy: {:.2f}%'.format(\n",
    "                    client.id,\n",
    "                    epoch, batch_idx * args.local_batches, len(train_loader) * args.local_batches, \n",
    "                    100. * batch_idx / len(train_loader),\n",
    "                    accuracy))\n",
    "    \n",
    "    # Return the collected training data and labels for potential aggregation\n",
    "    return np.array(X_train), np.array(y_train)\n",
    "\n",
    "\n",
    "def test(model, test_loader, name):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    X_test, y_test = [], []\n",
    "    for data, target in test_loader:\n",
    "        data = data.view(data.shape[0], -1).numpy()\n",
    "        X_test.extend(data)\n",
    "        y_test.extend(target.numpy())\n",
    "    \n",
    "    print(f\"Testing {name} model with {len(X_test)} samples\")\n",
    "    \n",
    "    # Measure prediction time\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    prediction_time = time.time() - start_time\n",
    "    print(f\"Prediction time: {prediction_time:.2f} seconds\")\n",
    "    \n",
    "    accuracy = (np.sum(y_pred == y_test) / len(y_test)) * 100\n",
    "    print(f'{name} Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "def aggregate_models(clients):\n",
    "    print(\"Aggregating models from clients\")\n",
    "    global_X_train, global_y_train = [], []\n",
    "    for client in clients:\n",
    "        train_loader = client.trainset\n",
    "        model = client.model\n",
    "        X_train, y_train = [], []\n",
    "        for data, target in train_loader:\n",
    "            data = data.view(data.shape[0], -1).numpy()\n",
    "            X_train.extend(data)\n",
    "            y_train.extend(target.numpy())\n",
    "        global_X_train.extend(X_train)\n",
    "        global_y_train.extend(y_train)\n",
    "    print(f\"Aggregated data size: {len(global_X_train)} samples\")\n",
    "    # Create a new KNN model and fit the aggregated data\n",
    "    global_model = KNN(k=args.k_neighbors)\n",
    "    global_model.fit(global_X_train, global_y_train)\n",
    "    print(\"Global model updated with aggregated data\")\n",
    "    return global_model\n",
    "\n",
    "\n",
    "# Main training loop\n",
    "global_model = KNN(k=args.k_neighbors)\n",
    "for fed_round in range(args.rounds):\n",
    "    # Select a subset of clients for the current round\n",
    "    num_selected_clients = int(args.C * args.clients)\n",
    "    selected_clients = random.sample(clients, num_selected_clients)\n",
    "    for client in selected_clients:\n",
    "        client_update(client)\n",
    "    # Aggregate client models and update the global model\n",
    "    global_model = aggregate_models(selected_clients)\n",
    "    # Test the global model\n",
    "    test(global_model, global_test_loader, \"Global\")\n",
    "\n",
    "    # Share the updated global model with all clients\n",
    "    for client in clients:\n",
    "        client.model = copy.deepcopy(global_model)\n",
    "\n",
    "if args.save_model:\n",
    "    torch.save(global_model, \"KNN.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5acb5f-ab5d-4cab-8142-1af89d4cd8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
