{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb32cf4-584c-46fe-82d3-4620f998f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import syft as sy\n",
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from FLDataset.FLDataset import load_dataset\n",
    "from FLDataset.FLDataset import getActualImgs\n",
    "from FLDataset.utils import averageModels\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688a97b5-1be7-47db-99ee-5c51bd54c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.images = 60000\n",
    "        self.clients = 10\n",
    "        self.rounds = 2\n",
    "        self.epochs = 2\n",
    "        self.local_batches = 1\n",
    "        self.lr = 0.01\n",
    "        self.C = 0.9\n",
    "        self.drop_rate = 0.1\n",
    "        self.mu = 0.1\n",
    "        self.torch_seed = 0\n",
    "        self.log_interval = 10\n",
    "        self.iid = 'iid'\n",
    "        self.split_size = int(self.images / self.clients)\n",
    "        self.samples = self.split_size / self.images \n",
    "        self.use_cuda = False\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ba5e1e-8fd4-47fe-9f33-24c09ca30b56",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset_ind_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_208753/2200749275.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mclient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trainset'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetActualImgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mclient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'testset'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetActualImgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mclient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset_ind_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainset_ind_list' is not defined"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "clients = []\n",
    "\n",
    "for i in range(args.clients):\n",
    "    clients.append({'hook': sy.VirtualWorker(hook, id=\"client{}\".format(i+1))})\n",
    "    \n",
    "global_train, global_test, train_group, test_group = load_dataset(args.clients, args.iid)\n",
    "\n",
    "for inx, client in enumerate(clients):\n",
    "    client['trainset'] = getActualImgs(global_train, list(train_group[inx])[:10], args.local_batches)\n",
    "    client['testset'] = getActualImgs(global_test, list(test_group[inx]), args.local_batches)\n",
    "    client['samples'] = len(client['trainset']) /20    #args.images \n",
    "   \n",
    "    \n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "global_test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "global_test_loader = DataLoader(global_test_dataset, batch_size=args.local_batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8133226-4183-4b0f-a48b-01d6755ac5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First convolutional layer\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "        # First fully connected layer\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a22eedb-13ad-4ec0-9bea-444c439ef612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedProxOptim(optim.Optimizer):\n",
    "    def __init__(self, params, lr=args.lr, mu=args.mu):\n",
    "        defaults = dict(lr=lr, mu=mu)\n",
    "        super(FedProxOptim, self).__init__(params, defaults)\n",
    "    \n",
    "    def step(self, global_model=None, closure = None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            lr, mu = group['lr'], group['mu']\n",
    "            for p in zip(group['params'], list(global_model.parameters())):\n",
    "                if p[0].grad is None:\n",
    "                    continue\n",
    "                d_p = p[0].grad.data # This is the local model gradients\n",
    "                p[0].data.sub_(group['lr'], (d_p + mu * (p[0].data.clone() - p[1].data.clone())))\n",
    "                \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eeef1a-f7a7-4c89-9d89-a70a4fc56d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientUpdate(args, device, client, global_model, rclients=False):\n",
    "    client['model'].train()\n",
    "    Epochs = args.epochs + 1\n",
    "    if rclients:\n",
    "        Epochs = np.random.randint(low=1, high=Epochs)\n",
    "        Epochs = 2\n",
    "\n",
    "    for epoch in range(1, Epochs):\n",
    "        for batch_idx, (data, target) in enumerate(client['trainset']):\n",
    "            data = data.send(client['hook'])\n",
    "            target = target.send(client['hook'])\n",
    "            client['model'].send(data.location)\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            client['optim'].zero_grad()\n",
    "            output = client['model'](data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            client['optim'].step(global_model.send(client['hook']))\n",
    "            client['model'].get() \n",
    "            global_model.get()\n",
    "\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                loss = loss.get() \n",
    "                print('Model {} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    client['hook'].id,\n",
    "                    epoch, batch_idx * args.local_batches, len(client['trainset']) * args.local_batches, \n",
    "                    100. * batch_idx / len(client['trainset']), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f757d5-9be6-449f-affc-3e2addc79351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the test function that will be implemented\n",
    "\n",
    "def test(args, model, device, test_loader, name):\n",
    "    model.eval()   \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss for {} model: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        name, test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766157c9-fb56-4b65-b1c1-0bb555012ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.torch_seed)\n",
    "global_model = Net()\n",
    "\n",
    "for client in clients:\n",
    "    torch.manual_seed(args.torch_seed)\n",
    "    client['model'] = Net().to(device)\n",
    "    client['optim'] = FedProxOptim(client['model'].parameters(), lr=args.lr, mu = args.mu)\n",
    "\n",
    "for fed_round in range(args.rounds):\n",
    "\n",
    "    # number of selected clients\n",
    "    m = int(max(args.C * args.clients, 1)) # m is the number of selected devices to be included in a specific round\n",
    "\n",
    "    # Selected devices\n",
    "    np.random.seed(fed_round)\n",
    "    selected_clients_inds = np.random.choice(range(len(clients)), m, replace=False)\n",
    "    selected_clients = [clients[i] for i in selected_clients_inds]\n",
    "    \n",
    "    # Active devices\n",
    "    active_clients_inds = np.random.choice(selected_clients_inds, int((1-args.drop_rate) * m), replace=False)\n",
    "    active_clients = [clients[i] for i in active_clients_inds]\n",
    "    \n",
    "    # The rest of the active devices (selected but dropped)\n",
    "    rest_clients_inds = np.setdiff1d(selected_clients_inds, active_clients_inds)\n",
    "    rest_clients = [clients[i] for i in rest_clients_inds]\n",
    "    \n",
    "    # Training the active devices\n",
    "    for client in active_clients:\n",
    "        ClientUpdate(args, device, client, global_model)\n",
    "    \n",
    "\n",
    "    # Training the rest with less number of epochs\n",
    "    for client in rest_clients:\n",
    "        ClientUpdate(args, device, client, global_model, True)\n",
    "        \n",
    "    global_model = averageModels(global_model, selected_clients)\n",
    "    \n",
    "    test(args, global_model, device, global_test_loader, 'Global')\n",
    "    \n",
    "    for client in clients:\n",
    "        client['model'].load_state_dict(global_model.state_dict())\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(global_model.state_dict(), \"FedProx.pt\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5fa4cc-ec18-4cac-a325-bd70827e3197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95e44c8-b60c-4628-9ccb-070841222ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b96545-5772-401d-9cbf-2dbeab34fe85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee982b2-ff64-4a74-82be-226c09c61c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
